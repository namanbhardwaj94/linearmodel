{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.6 64-bit",
   "display_name": "Python 3.7.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "0600588c3b5f4418cbe7b5ebc6825b479f3bc010269d8b60d75058cdd010adfe"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   YearBuilt  2ndFlrSF  GrLivArea  FullBath  HalfBath  BedroomAbvGr  \\\n0       2003       854       1710         2         1             3   \n1       1976         0       1262         2         0             3   \n2       2001       866       1786         2         1             3   \n3       1915       756       1717         1         0             3   \n4       2000      1053       2198         2         1             4   \n\n   TotRmsAbvGrd  YrSold  SalePrice  \n0             8    2008     208500  \n1             6    2007     181500  \n2             6    2008     223500  \n3             7    2006     140000  \n4             9    2008     250000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>YearBuilt</th>\n      <th>2ndFlrSF</th>\n      <th>GrLivArea</th>\n      <th>FullBath</th>\n      <th>HalfBath</th>\n      <th>BedroomAbvGr</th>\n      <th>TotRmsAbvGrd</th>\n      <th>YrSold</th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2003</td>\n      <td>854</td>\n      <td>1710</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>8</td>\n      <td>2008</td>\n      <td>208500</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1976</td>\n      <td>0</td>\n      <td>1262</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>6</td>\n      <td>2007</td>\n      <td>181500</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2001</td>\n      <td>866</td>\n      <td>1786</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>6</td>\n      <td>2008</td>\n      <td>223500</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1915</td>\n      <td>756</td>\n      <td>1717</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>7</td>\n      <td>2006</td>\n      <td>140000</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2000</td>\n      <td>1053</td>\n      <td>2198</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>9</td>\n      <td>2008</td>\n      <td>250000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "df = pd.read_csv('HousingPrices.csv')\n",
    "X = df.drop(columns=['SalePrice'])\n",
    "ydf = df[['SalePrice']]\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1460 1460\n"
    }
   ],
   "source": [
    "print(len(X),len(ydf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(X, ydf, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xval, x_test, yval, y_test = train_test_split(xtest, ytest, test_size = 0.5)\n",
    "\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: &quot;sequential_2&quot;\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_6 (Dense)              (None, 8)                 72        \n_________________________________________________________________\ndense_7 (Dense)              (None, 8)                 72        \n_________________________________________________________________\ndense_8 (Dense)              (None, 1)                 9         \n=================================================================\nTotal params: 153\nTrainable params: 153\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "\n",
    "    \n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Dense(units= 8,activation= 'relu', input_shape = (8,)))\n",
    "    model.add(keras.layers.Dense(units= 8, activation= 'relu'))\n",
    "    model.add(keras.layers.Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error',metrics=['acc'])\n",
    "    model.summary()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "795200.0000 - val_acc: 0.0000e+00\nEpoch 1877/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2690411776.0000 - acc: 0.0000e+00 - val_loss: 1995948288.0000 - val_acc: 0.0000e+00\nEpoch 1878/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2689837312.0000 - acc: 0.0000e+00 - val_loss: 1995671936.0000 - val_acc: 0.0000e+00\nEpoch 1879/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2691956480.0000 - acc: 0.0000e+00 - val_loss: 1997536384.0000 - val_acc: 0.0000e+00\nEpoch 1880/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2693609984.0000 - acc: 0.0000e+00 - val_loss: 1995379328.0000 - val_acc: 0.0000e+00\nEpoch 1881/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2691308032.0000 - acc: 0.0000e+00 - val_loss: 1996138368.0000 - val_acc: 0.0000e+00\nEpoch 1882/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2690451200.0000 - acc: 0.0000e+00 - val_loss: 1994839040.0000 - val_acc: 0.0000e+00\nEpoch 1883/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2682662400.0000 - acc: 0.0000e+00 - val_loss: 2000433152.0000 - val_acc: 0.0000e+00\nEpoch 1884/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2694112512.0000 - acc: 0.0000e+00 - val_loss: 1998583424.0000 - val_acc: 0.0000e+00\nEpoch 1885/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2689286400.0000 - acc: 0.0000e+00 - val_loss: 1995480576.0000 - val_acc: 0.0000e+00\nEpoch 1886/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2690313728.0000 - acc: 0.0000e+00 - val_loss: 1994794240.0000 - val_acc: 0.0000e+00\nEpoch 1887/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2689595136.0000 - acc: 0.0000e+00 - val_loss: 1997234944.0000 - val_acc: 0.0000e+00\nEpoch 1888/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2689099520.0000 - acc: 0.0000e+00 - val_loss: 1994698624.0000 - val_acc: 0.0000e+00\nEpoch 1889/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2686712320.0000 - acc: 0.0000e+00 - val_loss: 1996456576.0000 - val_acc: 0.0000e+00\nEpoch 1890/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2694520320.0000 - acc: 0.0000e+00 - val_loss: 1996240896.0000 - val_acc: 0.0000e+00\nEpoch 1891/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2692275968.0000 - acc: 0.0000e+00 - val_loss: 1994038784.0000 - val_acc: 0.0000e+00\nEpoch 1892/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2689969408.0000 - acc: 0.0000e+00 - val_loss: 1994672512.0000 - val_acc: 0.0000e+00\nEpoch 1893/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2686702080.0000 - acc: 0.0000e+00 - val_loss: 1993819648.0000 - val_acc: 0.0000e+00\nEpoch 1894/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2688212736.0000 - acc: 0.0000e+00 - val_loss: 1994559488.0000 - val_acc: 0.0000e+00\nEpoch 1895/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2687934208.0000 - acc: 0.0000e+00 - val_loss: 1993305728.0000 - val_acc: 0.0000e+00\nEpoch 1896/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2685592576.0000 - acc: 0.0000e+00 - val_loss: 1994407040.0000 - val_acc: 0.0000e+00\nEpoch 1897/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2689495552.0000 - acc: 0.0000e+00 - val_loss: 1993886848.0000 - val_acc: 0.0000e+00\nEpoch 1898/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2685840896.0000 - acc: 0.0000e+00 - val_loss: 1993923840.0000 - val_acc: 0.0000e+00\nEpoch 1899/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2687808768.0000 - acc: 0.0000e+00 - val_loss: 1993136896.0000 - val_acc: 0.0000e+00\nEpoch 1900/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2688875776.0000 - acc: 0.0000e+00 - val_loss: 1993087744.0000 - val_acc: 0.0000e+00\nEpoch 1901/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2687469824.0000 - acc: 0.0000e+00 - val_loss: 1993307520.0000 - val_acc: 0.0000e+00\nEpoch 1902/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2686805760.0000 - acc: 0.0000e+00 - val_loss: 1992456704.0000 - val_acc: 0.0000e+00\nEpoch 1903/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2686979328.0000 - acc: 0.0000e+00 - val_loss: 1993320064.0000 - val_acc: 0.0000e+00\nEpoch 1904/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2684333568.0000 - acc: 0.0000e+00 - val_loss: 1993059712.0000 - val_acc: 0.0000e+00\nEpoch 1905/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2684651008.0000 - acc: 0.0000e+00 - val_loss: 1992128768.0000 - val_acc: 0.0000e+00\nEpoch 1906/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2685085184.0000 - acc: 0.0000e+00 - val_loss: 1992622976.0000 - val_acc: 0.0000e+00\nEpoch 1907/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2688142080.0000 - acc: 0.0000e+00 - val_loss: 1991928320.0000 - val_acc: 0.0000e+00\nEpoch 1908/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2683999232.0000 - acc: 0.0000e+00 - val_loss: 1992265856.0000 - val_acc: 0.0000e+00\nEpoch 1909/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2687153408.0000 - acc: 0.0000e+00 - val_loss: 1992328064.0000 - val_acc: 0.0000e+00\nEpoch 1910/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2693071616.0000 - acc: 0.0000e+00 - val_loss: 1991366144.0000 - val_acc: 0.0000e+00\nEpoch 1911/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2686919680.0000 - acc: 0.0000e+00 - val_loss: 1994877440.0000 - val_acc: 0.0000e+00\nEpoch 1912/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2680875264.0000 - acc: 0.0000e+00 - val_loss: 1991249664.0000 - val_acc: 0.0000e+00\nEpoch 1913/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2685486592.0000 - acc: 0.0000e+00 - val_loss: 1991260672.0000 - val_acc: 0.0000e+00\nEpoch 1914/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2682485504.0000 - acc: 0.0000e+00 - val_loss: 1991687296.0000 - val_acc: 0.0000e+00\nEpoch 1915/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2685417472.0000 - acc: 0.0000e+00 - val_loss: 1991591296.0000 - val_acc: 0.0000e+00\nEpoch 1916/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2683430656.0000 - acc: 0.0000e+00 - val_loss: 1992539648.0000 - val_acc: 0.0000e+00\nEpoch 1917/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2684501760.0000 - acc: 0.0000e+00 - val_loss: 1991079680.0000 - val_acc: 0.0000e+00\nEpoch 1918/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2688586240.0000 - acc: 0.0000e+00 - val_loss: 1990259584.0000 - val_acc: 0.0000e+00\nEpoch 1919/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2682735616.0000 - acc: 0.0000e+00 - val_loss: 1991941120.0000 - val_acc: 0.0000e+00\nEpoch 1920/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2685058560.0000 - acc: 0.0000e+00 - val_loss: 1990934272.0000 - val_acc: 0.0000e+00\nEpoch 1921/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2682826496.0000 - acc: 0.0000e+00 - val_loss: 1991201152.0000 - val_acc: 0.0000e+00\nEpoch 1922/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2689323520.0000 - acc: 0.0000e+00 - val_loss: 1989768064.0000 - val_acc: 0.0000e+00\nEpoch 1923/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2687133184.0000 - acc: 0.0000e+00 - val_loss: 1991686784.0000 - val_acc: 0.0000e+00\nEpoch 1924/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2682981632.0000 - acc: 0.0000e+00 - val_loss: 1989598208.0000 - val_acc: 0.0000e+00\nEpoch 1925/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2680725504.0000 - acc: 0.0000e+00 - val_loss: 1989773056.0000 - val_acc: 0.0000e+00\nEpoch 1926/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2689017344.0000 - acc: 0.0000e+00 - val_loss: 1991246080.0000 - val_acc: 0.0000e+00\nEpoch 1927/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2683337728.0000 - acc: 0.0000e+00 - val_loss: 1989306624.0000 - val_acc: 0.0000e+00\nEpoch 1928/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2685248000.0000 - acc: 0.0000e+00 - val_loss: 1990607488.0000 - val_acc: 0.0000e+00\nEpoch 1929/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2681562368.0000 - acc: 0.0000e+00 - val_loss: 1990004864.0000 - val_acc: 0.0000e+00\nEpoch 1930/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2681792512.0000 - acc: 0.0000e+00 - val_loss: 1988977408.0000 - val_acc: 0.0000e+00\nEpoch 1931/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2680481536.0000 - acc: 0.0000e+00 - val_loss: 1988890112.0000 - val_acc: 0.0000e+00\nEpoch 1932/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2681543168.0000 - acc: 0.0000e+00 - val_loss: 1988298496.0000 - val_acc: 0.0000e+00\nEpoch 1933/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2681359104.0000 - acc: 0.0000e+00 - val_loss: 1989936640.0000 - val_acc: 0.0000e+00\nEpoch 1934/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2685438464.0000 - acc: 0.0000e+00 - val_loss: 1991666432.0000 - val_acc: 0.0000e+00\nEpoch 1935/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2680583424.0000 - acc: 0.0000e+00 - val_loss: 1988083456.0000 - val_acc: 0.0000e+00\nEpoch 1936/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2679211008.0000 - acc: 0.0000e+00 - val_loss: 1988389888.0000 - val_acc: 0.0000e+00\nEpoch 1937/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2680922624.0000 - acc: 0.0000e+00 - val_loss: 1987601664.0000 - val_acc: 0.0000e+00\nEpoch 1938/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2679991296.0000 - acc: 0.0000e+00 - val_loss: 1990721536.0000 - val_acc: 0.0000e+00\nEpoch 1939/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2681929472.0000 - acc: 0.0000e+00 - val_loss: 1987712896.0000 - val_acc: 0.0000e+00\nEpoch 1940/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2682112256.0000 - acc: 0.0000e+00 - val_loss: 1988109312.0000 - val_acc: 0.0000e+00\nEpoch 1941/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2685687040.0000 - acc: 0.0000e+00 - val_loss: 1987547776.0000 - val_acc: 0.0000e+00\nEpoch 1942/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2678920704.0000 - acc: 0.0000e+00 - val_loss: 1987258880.0000 - val_acc: 0.0000e+00\nEpoch 1943/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2677915648.0000 - acc: 0.0000e+00 - val_loss: 1988094720.0000 - val_acc: 0.0000e+00\nEpoch 1944/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2683618304.0000 - acc: 0.0000e+00 - val_loss: 1987402112.0000 - val_acc: 0.0000e+00\nEpoch 1945/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2677482240.0000 - acc: 0.0000e+00 - val_loss: 1987752832.0000 - val_acc: 0.0000e+00\nEpoch 1946/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2678452736.0000 - acc: 0.0000e+00 - val_loss: 1986501632.0000 - val_acc: 0.0000e+00\nEpoch 1947/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2683199488.0000 - acc: 0.0000e+00 - val_loss: 1988160256.0000 - val_acc: 0.0000e+00\nEpoch 1948/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2682032896.0000 - acc: 0.0000e+00 - val_loss: 1986473984.0000 - val_acc: 0.0000e+00\nEpoch 1949/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2677055232.0000 - acc: 0.0000e+00 - val_loss: 1986756864.0000 - val_acc: 0.0000e+00\nEpoch 1950/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2684000000.0000 - acc: 0.0000e+00 - val_loss: 1986031616.0000 - val_acc: 0.0000e+00\nEpoch 1951/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2677423104.0000 - acc: 0.0000e+00 - val_loss: 1986088192.0000 - val_acc: 0.0000e+00\nEpoch 1952/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2677958400.0000 - acc: 0.0000e+00 - val_loss: 1985593088.0000 - val_acc: 0.0000e+00\nEpoch 1953/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2680760064.0000 - acc: 0.0000e+00 - val_loss: 1986880000.0000 - val_acc: 0.0000e+00\nEpoch 1954/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2677574400.0000 - acc: 0.0000e+00 - val_loss: 1986306816.0000 - val_acc: 0.0000e+00\nEpoch 1955/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2680197120.0000 - acc: 0.0000e+00 - val_loss: 1985169664.0000 - val_acc: 0.0000e+00\nEpoch 1956/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2678979072.0000 - acc: 0.0000e+00 - val_loss: 1986814464.0000 - val_acc: 0.0000e+00\nEpoch 1957/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2677923840.0000 - acc: 0.0000e+00 - val_loss: 1986278144.0000 - val_acc: 0.0000e+00\nEpoch 1958/2000\n37/37 [==============================] - 0s 997us/step - loss: 2680546816.0000 - acc: 0.0000e+00 - val_loss: 1984832896.0000 - val_acc: 0.0000e+00\nEpoch 1959/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2682573312.0000 - acc: 0.0000e+00 - val_loss: 1985980288.0000 - val_acc: 0.0000e+00\nEpoch 1960/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2676848128.0000 - acc: 0.0000e+00 - val_loss: 1984562048.0000 - val_acc: 0.0000e+00\nEpoch 1961/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2676221696.0000 - acc: 0.0000e+00 - val_loss: 1984690816.0000 - val_acc: 0.0000e+00\nEpoch 1962/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2677960192.0000 - acc: 0.0000e+00 - val_loss: 1984880256.0000 - val_acc: 0.0000e+00\nEpoch 1963/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2674793728.0000 - acc: 0.0000e+00 - val_loss: 1985586176.0000 - val_acc: 0.0000e+00\nEpoch 1964/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2677748224.0000 - acc: 0.0000e+00 - val_loss: 1984088064.0000 - val_acc: 0.0000e+00\nEpoch 1965/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2680257536.0000 - acc: 0.0000e+00 - val_loss: 1984258560.0000 - val_acc: 0.0000e+00\nEpoch 1966/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2674617856.0000 - acc: 0.0000e+00 - val_loss: 1983973120.0000 - val_acc: 0.0000e+00\nEpoch 1967/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2675422464.0000 - acc: 0.0000e+00 - val_loss: 1984128256.0000 - val_acc: 0.0000e+00\nEpoch 1968/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2674173184.0000 - acc: 0.0000e+00 - val_loss: 1983575168.0000 - val_acc: 0.0000e+00\nEpoch 1969/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2675484928.0000 - acc: 0.0000e+00 - val_loss: 1983540608.0000 - val_acc: 0.0000e+00\nEpoch 1970/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2677832960.0000 - acc: 0.0000e+00 - val_loss: 1983718400.0000 - val_acc: 0.0000e+00\nEpoch 1971/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2677711104.0000 - acc: 0.0000e+00 - val_loss: 1983319168.0000 - val_acc: 0.0000e+00\nEpoch 1972/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2674723840.0000 - acc: 0.0000e+00 - val_loss: 1984724352.0000 - val_acc: 0.0000e+00\nEpoch 1973/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2674727936.0000 - acc: 0.0000e+00 - val_loss: 1983418368.0000 - val_acc: 0.0000e+00\nEpoch 1974/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2673363712.0000 - acc: 0.0000e+00 - val_loss: 1983561984.0000 - val_acc: 0.0000e+00\nEpoch 1975/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2673858560.0000 - acc: 0.0000e+00 - val_loss: 1983259904.0000 - val_acc: 0.0000e+00\nEpoch 1976/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2672507648.0000 - acc: 0.0000e+00 - val_loss: 1983374080.0000 - val_acc: 0.0000e+00\nEpoch 1977/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2674087936.0000 - acc: 0.0000e+00 - val_loss: 1982681472.0000 - val_acc: 0.0000e+00\nEpoch 1978/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2672539648.0000 - acc: 0.0000e+00 - val_loss: 1982450560.0000 - val_acc: 0.0000e+00\nEpoch 1979/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2672564736.0000 - acc: 0.0000e+00 - val_loss: 1982065792.0000 - val_acc: 0.0000e+00\nEpoch 1980/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2675519488.0000 - acc: 0.0000e+00 - val_loss: 1982102912.0000 - val_acc: 0.0000e+00\nEpoch 1981/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2676690688.0000 - acc: 0.0000e+00 - val_loss: 1982139008.0000 - val_acc: 0.0000e+00\nEpoch 1982/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2677526528.0000 - acc: 0.0000e+00 - val_loss: 1981993600.0000 - val_acc: 0.0000e+00\nEpoch 1983/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2682302720.0000 - acc: 0.0000e+00 - val_loss: 1981264640.0000 - val_acc: 0.0000e+00\nEpoch 1984/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2675712768.0000 - acc: 0.0000e+00 - val_loss: 1986210944.0000 - val_acc: 0.0000e+00\nEpoch 1985/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2671577600.0000 - acc: 0.0000e+00 - val_loss: 1981828864.0000 - val_acc: 0.0000e+00\nEpoch 1986/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2671936000.0000 - acc: 0.0000e+00 - val_loss: 1981644288.0000 - val_acc: 0.0000e+00\nEpoch 1987/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2676173312.0000 - acc: 0.0000e+00 - val_loss: 1981957248.0000 - val_acc: 0.0000e+00\nEpoch 1988/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2674634240.0000 - acc: 0.0000e+00 - val_loss: 1981147264.0000 - val_acc: 0.0000e+00\nEpoch 1989/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2673367040.0000 - acc: 0.0000e+00 - val_loss: 1980984064.0000 - val_acc: 0.0000e+00\nEpoch 1990/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2670868736.0000 - acc: 0.0000e+00 - val_loss: 1981688576.0000 - val_acc: 0.0000e+00\nEpoch 1991/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2672553216.0000 - acc: 0.0000e+00 - val_loss: 1981330304.0000 - val_acc: 0.0000e+00\nEpoch 1992/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2674418432.0000 - acc: 0.0000e+00 - val_loss: 1981460480.0000 - val_acc: 0.0000e+00\nEpoch 1993/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2673380352.0000 - acc: 0.0000e+00 - val_loss: 1982183936.0000 - val_acc: 0.0000e+00\nEpoch 1994/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2671149312.0000 - acc: 0.0000e+00 - val_loss: 1980402944.0000 - val_acc: 0.0000e+00\nEpoch 1995/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2671255040.0000 - acc: 0.0000e+00 - val_loss: 1980028160.0000 - val_acc: 0.0000e+00\nEpoch 1996/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2669781504.0000 - acc: 0.0000e+00 - val_loss: 1980633216.0000 - val_acc: 0.0000e+00\nEpoch 1997/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2672026880.0000 - acc: 0.0000e+00 - val_loss: 1981808640.0000 - val_acc: 0.0000e+00\nEpoch 1998/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2670414592.0000 - acc: 0.0000e+00 - val_loss: 1979666816.0000 - val_acc: 0.0000e+00\nEpoch 1999/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2670263296.0000 - acc: 0.0000e+00 - val_loss: 1980136832.0000 - val_acc: 0.0000e+00\nEpoch 2000/2000\n37/37 [==============================] - 0s 1ms/step - loss: 2672077568.0000 - acc: 0.0000e+00 - val_loss: 1979828864.0000 - val_acc: 0.0000e+00\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "&lt;tensorflow.python.keras.callbacks.History at 0x20c4ef779c8&gt;"
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    " model.fit(xtrain,ytrain, epochs=2000,validation_data=(xval,yval) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      bedrooms  bathrooms  sqft_living  sqft_lot  floors  condition  \\\n860        2.0        1.0         1490      3825     1.0          3   \n3836       5.0        1.0         1590      6700     1.5          3   \n1891       3.0        2.5         1520      2208     2.0          3   \n4572       6.0        4.5         3830      4800     3.0          3   \n4453       3.0        1.0         1300      6710     1.0          4   \n\n      sqft_above  sqft_basement             street           city  \n860          860            630   7008 19th Ave NW        Seattle  \n3836        1090            500  10626 12th Ave SW        Seattle  \n1891        1040            480    2537 13th Ave W        Seattle  \n4572        3050            780     2425 3rd Ave W        Seattle  \n4453        1300              0   2760 72nd Ave SE  Mercer Island  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>sqft_living</th>\n      <th>sqft_lot</th>\n      <th>floors</th>\n      <th>condition</th>\n      <th>sqft_above</th>\n      <th>sqft_basement</th>\n      <th>street</th>\n      <th>city</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>860</th>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1490</td>\n      <td>3825</td>\n      <td>1.0</td>\n      <td>3</td>\n      <td>860</td>\n      <td>630</td>\n      <td>7008 19th Ave NW</td>\n      <td>Seattle</td>\n    </tr>\n    <tr>\n      <th>3836</th>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>1590</td>\n      <td>6700</td>\n      <td>1.5</td>\n      <td>3</td>\n      <td>1090</td>\n      <td>500</td>\n      <td>10626 12th Ave SW</td>\n      <td>Seattle</td>\n    </tr>\n    <tr>\n      <th>1891</th>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>1520</td>\n      <td>2208</td>\n      <td>2.0</td>\n      <td>3</td>\n      <td>1040</td>\n      <td>480</td>\n      <td>2537 13th Ave W</td>\n      <td>Seattle</td>\n    </tr>\n    <tr>\n      <th>4572</th>\n      <td>6.0</td>\n      <td>4.5</td>\n      <td>3830</td>\n      <td>4800</td>\n      <td>3.0</td>\n      <td>3</td>\n      <td>3050</td>\n      <td>780</td>\n      <td>2425 3rd Ave W</td>\n      <td>Seattle</td>\n    </tr>\n    <tr>\n      <th>4453</th>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1300</td>\n      <td>6710</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>1300</td>\n      <td>0</td>\n      <td>2760 72nd Ave SE</td>\n      <td>Mercer Island</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 80
    }
   ],
   "source": [
    "xval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   bedrooms  bathrooms  sqft_living  sqft_lot  floors  condition  sqft_above  \\\n0       3.0       1.50         1340      7912     1.5          3        1340   \n1       5.0       2.50         3650      9050     2.0          5        3370   \n2       3.0       2.00         1930     11947     1.0          4        1930   \n3       3.0       2.25         2000      8030     1.0          4        1000   \n4       4.0       2.50         1940     10500     1.0          4        1140   \n\n   sqft_basement                    street       city  \n0              0      18810 Densmore Ave N  Shoreline  \n1            280           709 W Blaine St    Seattle  \n2              0  26206-26214 143rd Ave SE       Kent  \n3           1000           857 170th Pl NE   Bellevue  \n4            800         9105 170th Ave NE    Redmond  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>bedrooms</th>\n      <th>bathrooms</th>\n      <th>sqft_living</th>\n      <th>sqft_lot</th>\n      <th>floors</th>\n      <th>condition</th>\n      <th>sqft_above</th>\n      <th>sqft_basement</th>\n      <th>street</th>\n      <th>city</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3.0</td>\n      <td>1.50</td>\n      <td>1340</td>\n      <td>7912</td>\n      <td>1.5</td>\n      <td>3</td>\n      <td>1340</td>\n      <td>0</td>\n      <td>18810 Densmore Ave N</td>\n      <td>Shoreline</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5.0</td>\n      <td>2.50</td>\n      <td>3650</td>\n      <td>9050</td>\n      <td>2.0</td>\n      <td>5</td>\n      <td>3370</td>\n      <td>280</td>\n      <td>709 W Blaine St</td>\n      <td>Seattle</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3.0</td>\n      <td>2.00</td>\n      <td>1930</td>\n      <td>11947</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>1930</td>\n      <td>0</td>\n      <td>26206-26214 143rd Ave SE</td>\n      <td>Kent</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.0</td>\n      <td>2.25</td>\n      <td>2000</td>\n      <td>8030</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>1000</td>\n      <td>1000</td>\n      <td>857 170th Pl NE</td>\n      <td>Bellevue</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.0</td>\n      <td>2.50</td>\n      <td>1940</td>\n      <td>10500</td>\n      <td>1.0</td>\n      <td>4</td>\n      <td>1140</td>\n      <td>800</td>\n      <td>9105 170th Ave NE</td>\n      <td>Redmond</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      YearBuilt  2ndFlrSF  GrLivArea  FullBath  HalfBath  BedroomAbvGr  \\\n1053       1957         0       1526         1         0             4   \n864        2007         0       1372         2         0             3   \n185        1892      1518       3608         2         1             4   \n631        2006         0       1554         2         0             2   \n567        2004         0       1535         2         0             3   \n\n      TotRmsAbvGrd  YrSold  \n1053             7    2010  \n864              6    2008  \n185             12    2006  \n631              6    2007  \n567              7    2010  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>YearBuilt</th>\n      <th>2ndFlrSF</th>\n      <th>GrLivArea</th>\n      <th>FullBath</th>\n      <th>HalfBath</th>\n      <th>BedroomAbvGr</th>\n      <th>TotRmsAbvGrd</th>\n      <th>YrSold</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1053</th>\n      <td>1957</td>\n      <td>0</td>\n      <td>1526</td>\n      <td>1</td>\n      <td>0</td>\n      <td>4</td>\n      <td>7</td>\n      <td>2010</td>\n    </tr>\n    <tr>\n      <th>864</th>\n      <td>2007</td>\n      <td>0</td>\n      <td>1372</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>6</td>\n      <td>2008</td>\n    </tr>\n    <tr>\n      <th>185</th>\n      <td>1892</td>\n      <td>1518</td>\n      <td>3608</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>12</td>\n      <td>2006</td>\n    </tr>\n    <tr>\n      <th>631</th>\n      <td>2006</td>\n      <td>0</td>\n      <td>1554</td>\n      <td>2</td>\n      <td>0</td>\n      <td>2</td>\n      <td>6</td>\n      <td>2007</td>\n    </tr>\n    <tr>\n      <th>567</th>\n      <td>2004</td>\n      <td>0</td>\n      <td>1535</td>\n      <td>2</td>\n      <td>0</td>\n      <td>3</td>\n      <td>7</td>\n      <td>2010</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "x_test.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[[182982.14]]\n"
    }
   ],
   "source": [
    "test_data = np.array([2003,\t854,\t1710,\t2,\t1,\t3,\t8,\t2008])\n",
    "print(model.predict(test_data.reshape(1,8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      SalePrice\n1053     144500\n864      250580\n185      475000\n631      209500\n567      214000",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SalePrice</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1053</th>\n      <td>144500</td>\n    </tr>\n    <tr>\n      <th>864</th>\n      <td>250580</td>\n    </tr>\n    <tr>\n      <th>185</th>\n      <td>475000</td>\n    </tr>\n    <tr>\n      <th>631</th>\n      <td>209500</td>\n    </tr>\n    <tr>\n      <th>567</th>\n      <td>214000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}